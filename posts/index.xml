<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Dinis Peixoto</title>
        <link>https://dinispeixoto.com/posts/</link>
        <description>Recent content in Posts on Dinis Peixoto</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Sun, 18 Jun 2023 00:00:00 +0000</lastBuildDate>
        <atom:link href="https://dinispeixoto.com/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Linear Regression from scratch</title>
            <link>https://dinispeixoto.com/posts/linear-regression-from-scratch/</link>
            <pubDate>Sun, 18 Jun 2023 00:00:00 +0000</pubDate>
            
            <guid>https://dinispeixoto.com/posts/linear-regression-from-scratch/</guid>
            <description>Fundamentals Linear regression is a technique used to find the relationship between variables, in the context of machine learning that essentially means the relationship between features and labels.
It can be represented as follows:
$$ \hat{y} = \text{b} + w_1 x_1 + w_2 x_2 + \dots + w_n x_n $$ \(\hat{y}\) is the label \(\text{b}\) is the bias \(w_i\) is the weight of the feature i \(x_i\) is the feature value of feature i Loss Functions Loss is usually the metric we optimize the model for, it essentially tells us how wrong the model is - it measures the distance between the model&amp;rsquo;s predictions (\(\text{y}\)) and the actual labels (\(\hat{y}\)).</description>
            <content type="html"><![CDATA[<h3 id="fundamentals">Fundamentals</h3>
<p>Linear regression is a technique used to find the relationship between variables, in the context of machine learning that essentially means the relationship between features and labels.</p>
<p>It can be represented as follows:</p>
$$
\hat{y} = \text{b} + w_1 x_1 + w_2 x_2 + \dots + w_n x_n
$$
<ul>
<li>\(\hat{y}\) is the label</li>
<li>\(\text{b}\) is the bias</li>
<li>\(w_i\) is the weight of the feature i</li>
<li>\(x_i\) is the feature value of feature i</li>
</ul>
<h3 id="loss-functions">Loss Functions</h3>
<p>Loss is usually the metric we optimize the model for, it essentially tells us how wrong the model is - it measures the distance between the model&rsquo;s predictions (\(\text{y}\)) and the actual labels (\(\hat{y}\)). Something worth keeping in mind that is we don&rsquo;t really care about the direction, only the distance between the values, so loss functions usually removing the sign - i.e. 2 - 5 = -3, loss is 3.</p>
<table>
<thead>
<tr>
<th><strong>Loss Type</strong></th>
<th><strong>Definition</strong></th>
<th><strong>Equation</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>L1 Loss</strong></td>
<td>Sum of the absolute differences between predicted and actual values.</td>
<td>$$L = \sum_{i=1}^{N} \lvert y_i - \hat{y}_i \rvert$$</td>
</tr>
<tr>
<td><strong>L2 Loss</strong></td>
<td>Sum of the squared differences between predicted and actual values.</td>
<td>$$L = \sum_{i=1}^{N} (y_i - \hat{y}_i)^2$$</td>
</tr>
<tr>
<td><strong>Mean Absolute Error (MAE)</strong></td>
<td>Average of L1 loss across <em>N</em> examples.</td>
<td>$$MAE = \frac{1}{N} \sum_{i=1}^{N} \lvert y_i - \hat{y}_i \rvert$$</td>
</tr>
<tr>
<td><strong>Mean Squared Error (MSE)</strong></td>
<td>Average of L2 loss across <em>N</em> examples.</td>
<td>$$MSE = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2$$</td>
</tr>
</tbody>
</table>
<p>MSE is useful for outliers, it moves the model more towards it as it reduces the loss, while MAE might keep the model closer to predictions that are not necessarily an outlier.</p>
<h3 id="gradient-descent">Gradient Descent</h3>
<p>The goal of training model is essentially figuring out the values for \(\text{b}\) and \(w_i\) for every feature i that minimizes the loss function picked. This is where gradient descent comes in, it iteratively finds the weights and bias that produce the model with the lowest loss. It does so by doing the following process:</p>
<ol>
<li>Calculate loss with current weights and bias</li>
<li>For each weight and bias, determine the direction in which we should move them to reduce loss (opposite of the gradient)</li>
<li>For each weight and bias, update them by moving a small amount in the direction found</li>
<li>Return to step 1 and repeat until we the model can&rsquo;t reduce the loss any further</li>
</ol>
<h4 id="1-start-with-weight-and-bias-as-0">1. Start with weight and bias as 0</h4>
<p>We can assume that weights and bias can start as 0 when training starts.</p>
$$
\hat{y} = 0 + 0 \cdot x
$$
<h4 id="2-calculate-mse-loss-with-the-current-model-parameters">2. Calculate MSE loss with the current model parameters</h4>
<p>When calculating MSE for the model above, we would end up with something like the following if we assume expected values of 18, 15 and so on for our model.</p>
$$ Loss = ((18 - 0)^2 + (15 - 0)^2 ) + ... / N $$
<p>This is obviously not going to result in the best model predictions, so our goal now becomes finding which bias and weights take us to the best possible model, thus reducing the loss.</p>
<h4 id="3-calculate-the-slope-of-the-tangent-to-the-loss-function-for-each-weight-and-bias-ie-the-gradient">3. Calculate the slope of the tangent to the loss function for each weight and bias (i.e. the gradient)</h4>
<p>We can only optimize the loss if we understand exacly how to update each value, in this case weight and bias, in a way that results in a lower loss. This is where gradients come in.</p>
<p>The gradient is essentially how much y changes when x increases by 1, it tells us in which direction the function is taking us - e.g. m is the gradient in \(y = mx + b\).</p>
<p>To get the slope for the lines tangent to the weight and bias, we take the derivative of the loss function with respect to the weight and the bias, and then solve the equations.</p>
<p>Again, assuming we use MSE as our loss function \( \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 \) and \(y_i = w \cdot x + b\), as it represents our model.</p>
<p><strong>Weight derivative</strong></p>
<p>The weight derivative is \( \frac{\partial}{\partial w} ( (w \cdot x + b - y)^2 ) \), we can apply the <a href="https://en.wikipedia.org/wiki/Chain_rule">chain rule</a>.</p>
<p>We assume \(u^2\), where \(u = (w \cdot x + b - y)\)</p>
<p>So \( \frac{d}{dw} (u^2) = 2u \cdot \frac{du}{dw} \)</p>
<p>Since \(\frac{du}{dw} = x\)</p>
<p>It becomes \( \frac{d}{dw} ( (w \cdot x + b - y)^2 ) = 2(w \cdot x + b - y) \cdot x \).</p>
<p>We need to do this for every sample in the training dataset, so it&rsquo;s actually:</p>
$$ \frac{\partial \text{MSE}}{\partial w} = \frac{1}{M} \sum_{i=1}^{M} 2(w \cdot x^{(i)} + b - y^{(i)}) \cdot x^{(i)} $$
<p><strong>Bias derivative</strong></p>
<p>If we do the same for the bias, we would instead get:</p>
$$ \frac{\partial \text{MSE}}{\partial b} = \frac{1}{M} \sum_{i=1}^{M} 2(w \cdot x^{(i)} + b - y^{(i)}) $$
<h4 id="4-update-the-weights">4. Update the weights</h4>
<p>Well, now that we know exactly how to calculate the gradients, this should enable us to update both weight and bias in a way that optimizes loss.</p>
<p>The gradient tells us the opposite direction of where we have to go. An easy way to understand this is essentially thinking that if the gradient for a loss function is 5, every time we increase the weight by 1 unit, the loss will increase by 5, so essentially we want to do the opposite as our goal is to decrease the loss.</p>
$$ \text{new weight} = \text{old weight} - \eta \cdot \text{weight's gradient} $$
$$ \text{new bias} = \text{old bias} - \eta \cdot \text{bias' gradient} $$
<p>The small value used to update the gradient is the <em>learning rate</em>, which we will be leaving out of scope for now.</p>
<h4 id="5-model-training">5. Model Training</h4>
<p>After iteratively applying the steps above, model training would look something like this:</p>
<table>
<thead>
<tr>
<th>Iteration</th>
<th>Weight</th>
<th>Bias</th>
<th>Loss (MSE)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
<td>303.71</td>
</tr>
<tr>
<td>2</td>
<td>1.20</td>
<td>0.34</td>
<td>170.84</td>
</tr>
<tr>
<td>3</td>
<td>2.05</td>
<td>0.59</td>
<td>103.17</td>
</tr>
<tr>
<td>4</td>
<td>2.66</td>
<td>0.78</td>
<td>68.70</td>
</tr>
<tr>
<td>5</td>
<td>3.09</td>
<td>0.91</td>
<td>51.13</td>
</tr>
<tr>
<td>6</td>
<td>3.40</td>
<td>1.01</td>
<td>42.17</td>
</tr>
</tbody>
</table>
<h3 id="recap">Recap</h3>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Goal</strong></td>
<td>Find the best weights and bias that minimize the difference between predicted and actual values.</td>
</tr>
<tr>
<td><strong>Model Formula</strong></td>
<td>\( \hat{y} = w \cdot x + b \) — where <code>w</code> is weight, <code>x</code> is feature, and <code>b</code> is bias.</td>
</tr>
<tr>
<td><strong>Loss Functions</strong></td>
<td>Measure how wrong predictions are, e.g. MSE (\( \frac{1}{M} \sum (\hat{y} - y)^2 \)).</td>
</tr>
<tr>
<td><strong>Gradient Descent</strong></td>
<td>Iteratively updates weights using gradients: \( \frac{dL}{dw} = \frac{2}{M} \sum ((\hat{y} - y) \cdot x) \), \( \frac{dL}{db} = \frac{2}{M} \sum (\hat{y} - y) \). Update weights/bias in the opposite direction of gradients. Repeat until loss converges (stops decreasing significantly).</td>
</tr>
</tbody>
</table>
<h3 id="references">References</h3>
<ul>
<li><a href="https://developers.google.com/machine-learning/crash-course/linear-regression">Linear Regression</a></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Logistic Regression from scratch</title>
            <link>https://dinispeixoto.com/posts/logistic-regression-from-scratch/</link>
            <pubDate>Sun, 18 Jun 2023 00:00:00 +0000</pubDate>
            
            <guid>https://dinispeixoto.com/posts/logistic-regression-from-scratch/</guid>
            <description>Fundamentals Logistic Regression models, unlike Linear Regression, should help us predict the probability of a given outcome - e.g. if a payment is fraudulent or not. A Logistic Regression model, just like in Linear Regression can be represented as follows:
$$ \text{z} = \text{b} + w_1 x_1 + w_2 x_2 + \dots + w_n x_n $$ \(\text{z}\) is the output of the linear equation, also called the log odds. \(\text{b}\) is the bias.</description>
            <content type="html"><![CDATA[<h3 id="fundamentals">Fundamentals</h3>
<p>Logistic Regression models, unlike Linear Regression, should help us predict the probability of a given outcome - e.g. if a payment is fraudulent or not. A Logistic Regression model, just like in Linear Regression can be represented as follows:</p>
$$
\text{z} = \text{b} + w_1 x_1 + w_2 x_2 + \dots + w_n x_n
$$
<ul>
<li>\(\text{z}\) is the output of the linear equation, also called the log odds.</li>
<li>\(\text{b}\) is the bias.</li>
<li>The \(w_i\) values are the model&rsquo;s learned weights.</li>
<li>The \(x_i\) values are the feature values for a particular example.</li>
</ul>
<p>However we need to keep in mind that the output needs to be represented as a probability instead, i.e. a value between 0 and 1. This is where log-odds come in.</p>
<p>Let&rsquo;s start by understanding what odds are.</p>
<h4 id="odds">Odds</h4>
<p>The odds of an event are calculated as the probability of the event occurring divided by the probability of the event not occurring \((p / (1-p))\).</p>
<p>Odds are not probabilities, but the ratio of something happening vs the ratio of something not happening. Probabilities are the ratio of something happening to everything that could happen.</p>
<p>Example could be odds of a given team winning a game are 5:3, so 5/3 = 1.7. The probability of the team winning the same is 5/(5+3) = 5/8 = 0.625.</p>
<h4 id="log-odds">Log-odds</h4>
<p>The odds of a team losing will always be a number from 0 to 1, e.g. 1/3 or 1/20 or 1/100. While the odds of a team winning will always be a number from 1 to \((+\infty\)) - this creates asymmetry. This is where log(odds) comes into play, as by doing the log of the odds everything becomes symmetrical instead!</p>
<p>Let&rsquo;s consider two examples:</p>
<ul>
<li><strong>ratio of 1 to 6</strong>: log(1/6) = log(0.17) = -1.79</li>
<li><strong>ratio of 6 to 1</strong>: log(6/1) = log(6) = 1.79</li>
</ul>
<p>So if the logs are against, the log(odds) will be negative up to infinity, while if they are in favor we see the opposite. By using the log function we ensure that the distance from the origin (0) is the same for 1:6 and 6:1, which wouldn&rsquo;t be possible otherwise.</p>
<p>The log-odds is the natural logarithm of the odds, expressed as:</p>
$$ \text{logit}(p) = \log\left(\frac{p}{1 - p}\right) $$
<h4 id="sigmoid-function">Sigmoid function</h4>
<p>To go from log-odds back to probability, we can use the sigmoid function:</p>
$$ \text{y'} = \frac{1}{1 + e^{-z}} $$
<p>Something worth keeping in mind is that the linear function from the logistic regression model becomes input to the sigmoid function, which turns it into a s-shape function. The log-odds are transformed from really large numbers of z into probabilities between 0 and 1, exclusive.</p>
<p><img alt="sigmoid" src="/img/posts/logistic-regression/sigmoid.png"></p>
<p>So essentially the output of a logistic regression model is a log-odds, which can easily be transformed into a probability through the sigmoid function.</p>
<h3 id="loss-functions-log-loss">Loss Functions: Log loss</h3>
<p>The Log Loss equation returns the logarithm of the magnitude of the change, rather than just the distance from data to prediction.</p>
$$ \text{LogLoss}(y, \hat{y}) = - \left( y \cdot \log(\hat{y}) + (1 - y) \cdot \log(1 - \hat{y}) \right) $$
<p>It&rsquo;s worth understanding what would happen if we used the same loss function as a linear regression model, e.g. MSE. Let&rsquo;s assume we have 3 models - A, B and C, predicting 0.9, 0.6 and 0.0001, respectively for a true label example.</p>
<p><strong>Model A</strong>
</p>
$$ \text{MSE} = (0.9 - 1)^2 = 0.01 $$
$$ \text{LogLoss} = -\left(1 \cdot \log(0.9) + 0 \cdot \log(1 - 0.9)\right) = -\log(0.9) \approx 0.105 $$
<p><strong>Model B</strong>
</p>
$$ \text{MSE} = (0.6 - 1)^2 = 0.16 $$
$$ \text{LogLoss} = -\log(0.6) \approx -0.22 $$
<p><strong>Model C</strong>
</p>
$$ \text{MSE} = (0.0001 - 1)^2 \approx 0.99 $$
$$ \text{LogLoss} = -\log(0.0001) = -4 $$
<p>The difference in MSE for models A and B is just 0.15, which is incredibily small, even though model B is not doing a good job. MSE only sees “how close is the number to 1”, and 0.6 is numerically closer to 1 than, say, 0.2. It doesn’t understand that 0.6 means “not very confident”.</p>
<p>It&rsquo;s also possible to see in model C what happens when the model is incredibily wrong, for the possible label (y=1) the log loss becomes:</p>
$$ \text{LogLoss} = -\log(\hat{y}) $$
<p>So if the prediction is close to 0, the loss is going to be increasing towards \((+\infty\)). It&rsquo;s always worth checking how the log function works, for values from 1 and 0 in the x axis, y decreases rapidily, which is exactly what we are seeing here (although the inverse since the loss function is \(-\log(\text{x})\)). On the other hand, if the prediction is close to 1, the loss is going get closer to 0, as \(~log(1) = 0\).</p>
<p><img alt="log" src="/img/posts/logistic-regression/log.png"></p>
<p>Similarly, when predicting the negative label, it becomes:</p>
$$ \text{LogLoss} = -\log(1 - \hat{y}) $$
<p>So the log loss is essentially \(-\log(\hat{y})\) if y = 1 or \(-\log(1 - \hat{y})\) if y = 0, which makes it quite straightforward to understand.</p>
<h3 id="recap">Recap</h3>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Equation</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linear model</td>
<td>\( z = w \cdot x + b \)</td>
<td>Weighted sum of inputs</td>
</tr>
<tr>
<td>Log-odds</td>
<td>\( \log\left( \frac{p}{1 - p} \right) = z \)</td>
<td>The linear model predicts log-odds. The log-odds scale is unbounded (\(-\infty\) to \(+\infty\)) perfect for linear models</td>
</tr>
<tr>
<td>Probability (sigmoid)</td>
<td>\( p = \frac{1}{1 + e^{-z}} \)</td>
<td>Converts log-odds to probability. Probability scale is bounded (0 to 1)</td>
</tr>
<tr>
<td>Log loss</td>
<td>\( -y \log(\hat{p}) - (1 - y) \log(1 - \hat{p}) \)</td>
<td>Penalizes confident wrong predictions</td>
</tr>
</tbody>
</table>
<h3 id="references">References</h3>
<ul>
<li><a href="https://developers.google.com/machine-learning/crash-course/logistic-regression">Logistic Regression</a></li>
<li><a href="https://www.youtube.com/watch?v=ARfXDSkQf1Y">Odds and Log(Odds)</a></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>A year&#39;s worth of learnings from adopting Mob programming</title>
            <link>https://dinispeixoto.com/posts/a-years-worth-of-learnings-from-adopting-mob-programming/</link>
            <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
            
            <guid>https://dinispeixoto.com/posts/a-years-worth-of-learnings-from-adopting-mob-programming/</guid>
            <description>At FARFETCH, teams are encouraged to try new development methodologies so that they can deliver even better results while also improving productivity. As a fairly new team, we have continuously been looking for different methodologies that best fit our needs, such as avoiding knowledge silos or a slow-paced reviewing process. Although not every approach that we have tried has worked, the ones that did are now part of our daily development workflow and play a key role in the outcome of the tasks that we deliver.</description>
            <content type="html"><![CDATA[<p>At FARFETCH, teams are encouraged to try new development methodologies so that they can deliver even better results while also improving productivity. As a fairly new team, we have continuously been looking for different methodologies that best fit our needs, such as avoiding knowledge silos or a slow-paced reviewing process. Although not every approach that we have tried has worked, the ones that did are now part of our daily development workflow and play a key role in the outcome of the tasks that we deliver.</p>
<p>A year ago, our team was first introduced to <a href="https://mobprogramming.org/">Mob Programming</a>, and we have been using it since then. The concept that was once hard to fathom is now the go-to approach when dealing with most of our sprint tasks. Although being able to use Mob Programming daily has come with many different types of challenges, the results have been surprisingly good.</p>
<h2 id="whats-mob-programming">What&rsquo;s Mob Programming?</h2>
<p>When using Mob Programming, instead of having each team element working on its own task, the whole team gathers together to tackle the same task. It includes using a single workstation and only one person typing - <em>the Driver</em> - while the remaining people are describing the path that should be taken.</p>
<blockquote>
<p>It’s a software development approach where the whole team works on the same thing, at the same time, in the same space, and at the same computer. - Woody Zuill (2014)</p>
</blockquote>
<p>Mob Programming is somewhat similar to Pair Programming. While the latter consists of having two team members sharing the same workstation, Mob Programming goes a bit further and implies having the entire team focused on a single task. Even though Pair Programming is a great tool to share knowledge, improve communication and even bring better outcomes (as a consequence of having multiple people thinking about the same problem), it confines these advantages to only two elements on a team. On the other hand, Mob Programming can amplify these benefits to the whole team.</p>
<p>Yet, having an entire team working on the same problem brings its own challenges. It&rsquo;s imperative that the team establishes a set of well-defined procedures and rules. Furthermore, Mob Programming may not be suitable for all kinds of tasks or teams. Depending on the task the team is tackling, it should first be established whether Mob, Pair or Solo Programming is the appropriate methodology. None of the three is suitable for all situations. It&rsquo;s up to the teams to give them a try and figure out when to use them.</p>
<h2 id="how-does-it-work">How does it work?</h2>
<p>A typical Mob Programming setup consists of moving the team to an isolated space (e.g. a meeting room) and bringing one computer that should be connected to either a large monitor or a projector. Having a whiteboard to write down possible solutions and describe the next steps is great to empower collaborative brainstorming. Seats and tables for everyone is a must, as everyone should be comfortable during the session, this is particularly relevant as these sessions tend to be time-consuming. Since the beginning of the Covid-19 pandemic, we have adapted our ways of working to facilitate <a href="https://www.remotemobprogramming.org/">Remote Mob Programming</a> sessions - but more to come on that later.</p>
<p><img alt="Environment &amp; Setup" src="/img/posts/mob/mob.png"></p>
<p>Two key roles must be considered when using Mob Programming: the Driver and the Navigator. The Driver is the person at the keyboard, responsible for moving the codebase forward. The Navigator understands what the group has decided to aim for and provides instructions to the Driver. The Navigator shouldn&rsquo;t dictate the actual code that the Driver has to write down, only the expected solution. Sometimes, the Navigator role may not be needed. It is up to the Driver to opt-in or out. Nonetheless, when there&rsquo;s no Navigator, the Driver may get lost by having multiple people explaining what to do. These roles should rotate between all team members at regular intervals (usually monitored by a timer).</p>
<p>The session should be held continuously until the task is done. Quick breaks, like coffee or bathroom, are allowed and shouldn&rsquo;t require the session to stop. Some longer breaks like lunch must be agreed between the team so that everyone does it at the same time to prevent distractions and absences.</p>
<h2 id="what-about-productivity">What about productivity?</h2>
<p>The first thing that may come to one&rsquo;s mind is that Mob Programming jeopardizes the team&rsquo;s overall productivity. After all, having an entire team working on the same task certainly means that both the team&rsquo;s velocity and throughput will be compromised, right?</p>
<p>More often than not, people tend to forget that delivering a task includes a lot more than just writing code. It&rsquo;s common that most of the time spent on a particular task is on coming up with the right solution or waiting for the team to review what was done. In our case, each task requires approval from 3 different people, which implies that they stop what they are doing, get up to speed, and finally review the result.</p>
<p>When using a development workflow like Solo Programming, once a developer puts the task up for review, the team has to understand all the requirements and review what was done, while also trying to identify what was the problem-solving process that the author took. The fact that the team has to go through someone else’s work without being completely aware of the decisions behind the proposed solution might take longer and prevent some mistakes from being identified.</p>
<p>Whereas when using Mob Programming, taking advantage of insights and knowledge from the whole team may lead to the task being delivered quicker while also with a better solution. When it comes to the review process, it will also be straightforward as everyone owns the decisions that were made and the solution path that was taken.</p>
<h2 id="methodology-rules-and-tools">Methodology, Rules and Tools</h2>
<p>We have been using Mob Programming for over a year. Over this period, we have been trying to refine our methodology so that we can make the most out of our sessions. Some of the phases that have improved our workflow are described below.</p>
<ol>
<li>
<p><strong>Task scouting:</strong> each team member should, individually, check the task details prior to the session. Investing time on exploring the task beforehand will considerably shorten the time required on the next phase.</p>
</li>
<li>
<p><strong>Purpose clarification:</strong> at the beginning of the session, someone should present the problem at hand and make sure that everyone has a clear grasp of what the team is trying to achieve. Any questions about the purpose of the task should be raised at this time.</p>
</li>
<li>
<p><strong>Work breakdown:</strong> with the purpose of clarified, it&rsquo;s now time to identify the work blocks that have to be monitored during the session. The different tasks that result from this analysis should be prioritized and can be split into even smaller tasks if needed.</p>
</li>
<li>
<p><strong>Execution:</strong> based on the tasks identified previously, the team must try to work on each task by following the agreed order. The team should expect new tasks to surface throughout the session. If it happens, the order of the tasks can be adjusted.</p>
</li>
<li>
<p><strong>Debriefing:</strong> at the end of the session, the team will need to look at the initially defined tasks and check if everything was tackled. The solution should be carefully reviewed together before submitting it for team review. It&rsquo;s highly recommended to provide some time for an individual review to address groupthink problems.</p>
</li>
</ol>
<p>Equally important are the rules that our team has defined so far. Periodically, we revisit them and discuss whether or not some updates are required. Trying to make this an iterative process is extremely important to enhance the overall experience of our Mob Programming sessions over time.</p>
<ol>
<li>
<p><strong>Driving/navigation time:</strong> each team member will be in the Driver/Navigator role for 15 minutes. If a discussion comes up, the timer should stop so that both the Driver and Navigator can participate.</p>
</li>
<li>
<p><strong>Complete focus on the session:</strong> everyone in the room has to be focused on the session. If someone needs to work on something else, they must leave the room to avoid distracting the team.</p>
</li>
<li>
<p><strong>Mandatory and optional breaks:</strong> there are three mandatory breaks where the session must be stopped: morning coffee, lunch and afternoon coffee. Additional breaks are allowed but should be minimized to reduce the impact on focus. These sessions are very demanding on every team member so, if one cannot focus on the current tasks, taking a break is completely acceptable.</p>
</li>
<li>
<p><strong>Research time:</strong> whenever research is required, it should be done primarily by the Driver with the help of the team. Parallel research streams are allowed, as long as the team is aware of them.</p>
</li>
<li>
<p><strong>Identify Mob Programming tasks ahead of time:</strong> we always try to decide upon whether a specific task is going to be tackled through Mob Programming or not. It facilitates any coordination required during our sprint.</p>
</li>
</ol>
<p>Due to the COVID-19 global pandemic, we had a new challenge ahead of us: Remote Mob Programming. As a consequence, we had to go through the rules above and update them as a means to adapt to the reality of having the whole team working remotely.</p>
<ol>
<li>
<p><strong>Driving/navigation time:</strong> this should be increased, in our case, we adjusted it to 45 minutes, due to the extra work required when changing the Driver (e.g. setting up the environment, sync with git&rsquo;s remote repository). It might take up to 5 minutes and wouldn&rsquo;t be worth it to do it every 15 minutes.</p>
</li>
<li>
<p><strong>Video sharing:</strong> everyone should keep the camera on during the session and, when possible, look directly at it. It’s as close as we can get to face-to-face interaction.</p>
</li>
<li>
<p><strong>Driver handover:</strong> every time a Driver handover is required, the current Driver has to ensure that changes made during their turn are properly committed and pushed to the remote repository. To have a better sense of the changes and their history, usually, the Driver&rsquo;s name is kept on the commit description.</p>
</li>
</ol>
<p>When it comes to the tools that we use during our mob sessions, it depends on if we are doing it in-person or remotely. When having in-person sessions, the only tool that we make use of is Mobster, which allows us to keep track of the Driver timer, the active and next up Drivers. Whereas when having remote sessions, on top of <a href="https://github.com/dillonkearns/mobster">Mobster</a> we also benefit from <a href="https://slack.com/">Slack</a> for video/screen sharing and live annotations (i.e. being able to write on the Driver&rsquo;s screen) and from <a href="https://trello.com/">Trello</a> for task management.</p>
<h2 id="challenges">Challenges</h2>
<p>The main challenge that we are facing at the moment is trying to make sure that everyone equally contributes during these sessions. Different types of personalities lead to distinct forms of contributions, as not everyone is comfortable thriving in this type of environment. However, no opinion must be left behind. Everyone should share their point of view, or we wouldn’t be taking advantage of using this methodology. The Driver usually makes sure to ask each person&rsquo;s opinion to ensure that everyone is sharing their ideas and contributing to the session.</p>
<p>Dealing with different paces and knowledge levels is a continuous struggle until we have everyone at roughly the same level. One may be more comfortable with a particular programming language or technology but has to ensure that everyone else is capable of keeping up with what&rsquo;s being done during the session. Having a person with a preconceived solution and imposing the next steps on the Driver should be avoided. The solution should be discussed and agreed by the whole team so that any participant is capable of providing the following steps.</p>
<p>Yet another challenge is the potential bias that comes from reviewing tasks as a group. In order to tackle this particular issue, we usually try to enforce individual reviews on top of the Mob Review.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Being upfront, open and honest towards the team about our feelings regarding Mob Programming and what could be improved, has proven essential to be able to use it regularly. Adopting it and coming up with our own methodology, rules, and tools was not an easy task. In fact, it has been an iterative process, and we still feel that there are a lot of challenges to face ahead of us.</p>
<p>Nevertheless, the impact that Mob has had on the team has been really positive. Not too long after giving it a try, we noticed that knowledge was being spread throughout the team much quicker than before. We were now becoming a T-shaped team. For instance, due to previous experience, some team elements were more prone to DevOps tasks, e.g. handling the CI/CD environment, and they quickly started sharing their knowledge so that everyone could do it on their own.</p>
<p>On top of that, we have seen a marked improvement in code quality, which has resulted in very few bugs after live release. Every team member agrees that the real value of adopting Mob Programming comes with being able to build high-quality software while ensuring that everyone understands the codebase and the philosophy behind it.</p>
<p>Particularly during the COVID-19 pandemic, where everyone has been working remotely, having Remote Mob Programming sessions kept the team together. Since there&rsquo;s no in-person interaction during these sessions, we try to take advantage of the live annotations feature to make jokes and have some fun. We lose a bit of focus, but in return, the team feels closer, as if we were working together in-person.</p>
<p>Every two weeks, the team takes a brief look at performance metrics, like throughput and cycle time. During the switch to Mob Programming, we didn’t see a significant impact on them. Yet, the goal was never to ship code faster, but instead to improve the quality of our deliverables while also sharing knowledge across the team, even if our metrics could be compromised while doing so.</p>
<p>We would encourage teams to try Mob Programming and evaluate if the pros of adopting it outweigh the cons. We suggest that they start with tasks that tend to demand discussions and brainstorm, as it will have the most impact on those. We are confident that such a methodology is worth trying, and the output can be surprisingly good for any team.</p>
<p><em>Originally published at <a href="https://www.farfetchtechblog.com">https://www.farfetchtechblog.com</a> on December 16, 2020.</em></p>
]]></content>
        </item>
        
        <item>
            <title>Brand Recommendations - TF-IDF</title>
            <link>https://dinispeixoto.com/posts/brand-recommendations-tf-idf/</link>
            <pubDate>Fri, 13 Mar 2020 00:00:00 +0000</pubDate>
            
            <guid>https://dinispeixoto.com/posts/brand-recommendations-tf-idf/</guid>
            <description>I started learning about Machine Learning with a couple online courses. The thing with these courses is that I got to learn a lot of cool stuff supported with step-by-step tutorials, but I never took some time to actually build something on my own, that tackles a real issue that I&amp;rsquo;m facing.
This is where things get interesting. One of the initiatives that I had at the company I was working back then was around brand recommendations.</description>
            <content type="html"><![CDATA[<p>I started learning about Machine Learning with <a href="https://www.udemy.com/course/machinelearning/">a</a> <a href="https://www.udemy.com/course/deeplearning/">couple</a> online courses. The thing with these courses is that I got to learn a lot of cool stuff supported with step-by-step tutorials, but I never took some time to actually build something on my own, that tackles a real issue that I&rsquo;m facing.</p>
<p>This is where things get interesting. One of the initiatives that I had at the company I was working back then was around brand recommendations. So I started wondering how hard could it be to build a simple machine learning model to provide brand recommendations.</p>
<p>This blog post will describe all the steps that were taken to build a baseline model that provides brand recommendations for the top brands available on well knwon e-commerce marketplace. Please note that the approach used here is not rocket science.</p>
<h2 id="how-does-a-recommendations-system-work">How does a recommendations system work?</h2>
<p>I will start by briefly explaining how the two most common types of recommendation systems work. Let&rsquo;s consider the example of a platform like Medium that has to recommend articles to users. It can either recommend articles to users based on their content, or based on what similar users tend to read.</p>
<ul>
<li>
<p><strong>Collaborative Filtering</strong>: providing article recommendations based on what other similar users also read. Based on the interactions that users have with the same articles, the system provides article recommendations with more confidence</p>
</li>
<li>
<p><strong>Content-Based Filtering</strong>: providing article recommendations based on the content of the article. If users usually read articles about <em>machine learning</em>, they will be more likely to read other articles that share the same topic</p>
</li>
</ul>
<p><img alt="Recommendation Systems" src="/img/posts/brand-recommendations-tfidf/recommendation-systems.png"></p>
<p>Even though I find the Collaborative Filtering type of systems a lot more interesting, they are generally more challenging. I decided to start with a <strong>Content-Based Recommendations System</strong> as the only data that it will need are descriptions from products available on the website. Later on, I will consider building a Hybrid Recommendations System where both Content-Based and Collaborative Filtering can be used simultaneously.</p>
<p>The goal will be to build a Content-Based Brand Recommendations System that provides the Top N brand recommendations for a particular brand.</p>
<h2 id="term-frequency---inverse-document-frequency">Term Frequency - Inverse Document Frequency</h2>
<p>TF-IDF stands for <em>Term Frequency - Inverse Document Frequency</em> and is used to measure how important a keyword (or multiple keywords) is to a document in a collection of documents (e.g. blog posts on this website). TF-IDF is the product of two different frequencies:</p>
<ul>
<li>
<p><strong>Term Frequency</strong>: measures how frequent a term is in a document. It will increase if the number of times a term appears also increases.</p>
<p><code>TF(t) = Number of times term t appears in a document / Total number of terms in the document</code></p>
</li>
<li>
<p><strong>Inverse Document Frequency</strong>: measures how important a term is. It will increase if the number of documents that contain the term decreases, i.e. if a term is rare. Meaning that common English words (e.g. <em>the</em>, <em>or</em>, <em>a</em>) should be quite irrelevant as they will be common on all the documents (as long as those documents are written in English). On the other hand, if we consider all the articles on my blog, words like <em>brand</em>, <em>recommendations</em> and <em>machine-learning</em> will be particularly relevant for the article you are reading.</p>
<p><code>IDF(t) = log(Total number of documents / Number of documents with term t in it)</code></p>
<p>The logarithm is used to smooth the impact that higher values can have in the Inverse Document Frequency. Let&rsquo;s remove the <code>log</code> for a moment and consider a corpus that consists of one million documents where only one of them contains the term <em>machine-learning</em>. In this scenario we would have 1.000.000/1, thus an Inverse Document Frequency of 1.000.000, which in turn would make the Term Frequency completely useless.</p>
</li>
</ul>
<h3 id="tf-idf--tf-x-idf">TF-IDF = TF x IDF</h3>
<p>TF-IDF will give us the weight that each term has w.r.t. each particular document. We will consider each document to be a different brand. For each brand, we will build a brand description by merging some of their product descriptions. For the brand Adidas, we will bring together the descriptions of up to N products - stan smith, ultra boost, etc - and combine them into a brand description.</p>
<table>
<thead>
<tr>
<th></th>
<th>Term A</th>
<th>Term B</th>
<th>Term C</th>
</tr>
</thead>
<tbody>
<tr>
<td>Brand A</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Brand B</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>The result will be a <em>N_brands</em> x <em>N_terms</em> matrix, where each row is a vector that represents a given brand - <code>(weight_term_A, weight_term_B, weight_term_C)</code>. We won&rsquo;t be able to find which brands are related by only looking at this matrix. Instead, we need to find a way to build a matrix that compares each brand to every other brand - <em>N_brands</em> x <em>N_brands</em> - and this is where Cosine Similarities come in handy.</p>
<table>
<thead>
<tr>
<th></th>
<th>Brand A</th>
<th>Brand B</th>
</tr>
</thead>
<tbody>
<tr>
<td>Brand A</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Brand B</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="cosine-similarity">Cosine Similarity</h2>
<p>Well, we already have a vector for each of the brands. It&rsquo;s time to compare them to see which vectors are similar. Cosine Similarity is one of the most common strategies to compare how similar two vectors are. It is defined by the cosine of the angle between two vectors, and we will see later that it should be the same as the dot product of the two vectors when they are normalized, i.e. both have length 1.</p>
<p><img alt="Cosine Similarity" src="/img/posts/brand-recommendations-tfidf/cosine_similarity.png"></p>
<p>Even though the cosine values range from -1 to 1, we will never have negative values in our vectors. The range will always be from 0 to 1, where values near 1 will mean that the vectors are similar, i.e. the brands that those vectors correspond to are similar and can be recommended together.</p>
<p>The easiest way to see this in practice is to consider two vectors that denote the same brand, which is the same as saying two equal vectors. If they are the same, then the angle between the two is 0. The cosine of its angle <code>cos(0)</code> is 1. When building our <em>N_brands</em> x <em>N_brands</em> matrix, we will see that, for each brand, the most similar brand (where the cosine similarity is 1) is the brand itself.</p>
<table>
<thead>
<tr>
<th></th>
<th>Brand A</th>
<th>Brand B</th>
</tr>
</thead>
<tbody>
<tr>
<td>Brand A</td>
<td>1</td>
<td>?</td>
</tr>
<tr>
<td>Brand B</td>
<td>?</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>Let&rsquo;s now look at the cosine similarity formula. If our vectors are normalized, every vector has length 1, meaning that we can remove the fraction&rsquo;s denominator as it will also be 1. Without the denominator, the only thing left to calculate is the <em>dot product</em> of the vectors we want to compare.</p>
<p><img alt="Formula" src="/img/posts/brand-recommendations-tfidf/formula.png"></p>
<p>If you look closely, the dot product should be straightforward, as each <code>Ai x Bi</code> will be the multiplication of the weights of the term <code>i</code> for the brands A and B. The image below should help understanding how the dot product of two vectors works.</p>
<p><img alt="Formula" src="/img/posts/brand-recommendations-tfidf/dot_product.jpg"></p>
<p>So, for each brand, we will calculate the dot product that the brand&rsquo;s vector makes with every other brand&rsquo;s vector, which will result in the <em>N_brands</em> x <em>N_brands</em> matrix that we were seeking. To provide the Top N recommendations for a given brand, we will have to search for the brands that resulted in a higher dot product for the brand we are testing.</p>
<p>Looking at the example below, we can see that we would be more likely to recommend brand C (<code>0.8</code>) than brand B (<code>0.1</code>) to users that also like or buy products from brand A.</p>
<table>
<thead>
<tr>
<th></th>
<th>Brand A</th>
<th>Brand B</th>
<th>Brand C</th>
</tr>
</thead>
<tbody>
<tr>
<td>Brand A</td>
<td>1</td>
<td>0.1</td>
<td>0.8</td>
</tr>
<tr>
<td>Brand B</td>
<td>0.1</td>
<td>1</td>
<td>0.3</td>
</tr>
<tr>
<td>Brand C</td>
<td>0.8</td>
<td>0.3</td>
<td>1</td>
</tr>
</tbody>
</table>
<h2 id="step-by-step">Step by step</h2>
<p>Now that we have gone through the theory of how both TF-IDF and Cosine Similarities work, we can start describing step-by-step how to build the recommendations model. All the code described below is available in a <a href="https://github.com/dinispeixoto/related-brands-mlops">Github repository</a>.</p>
<h3 id="gather-data">Gather Data</h3>
<p>The first step was to gather the data that the model will be trained with. For the sake of simplicity let&rsquo;s assume that we had access to the data in a Neo4j instance. The data (brands, products and their descriptions) is available on the website and could be easily retrieved with a scrapper and then loaded into Neo4j.</p>
<p>The e-commerce website has thousands of brands available. It&rsquo;s critical to filter a subset of brands that can be appropriate for the model. I have concluded that it would be worth filtering the brands with a significant number of products, e.g. at least 1000 products. Funny enough, the result is around 1000 brands as well.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> neo4j <span style="color:#f92672">import</span> GraphDatabase
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>db <span style="color:#f92672">=</span> GraphDatabase<span style="color:#f92672">.</span>driver(<span style="color:#e6db74">&#34;bolt://hostname:port&#34;</span>, auth<span style="color:#f92672">=</span>(username, password))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>MIN_PRODUCTS <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>statement <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">MATCH (brand:Brand)-[has_product:HAS_PRODUCT]-&gt;(product:Product)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">WHERE count(has_product) &gt; </span><span style="color:#e6db74">{</span>MIN_PRODUCTS<span style="color:#e6db74">}</span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">RETURN brand
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>brands <span style="color:#f92672">=</span> db<span style="color:#f92672">.</span>session()<span style="color:#f92672">.</span>run(statement)
</span></span><span style="display:flex;"><span>filtered_brand_ids <span style="color:#f92672">=</span> [brand[<span style="color:#e6db74">&#39;brandId&#39;</span>]) <span style="color:#66d9ef">for</span> brand <span style="color:#f92672">in</span> brands]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Total filtered brands: </span><span style="color:#e6db74">{</span>len(filtered_brand_ids)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>As soon as we have the brands that will be used by our model, it&rsquo;s time to gather the descriptions from up to 20000 of their products. A CSV file is created with the brand identifiers (id and name) and their corresponding description - i.e. the result of merging the descriptions from their products.</p>
<p>Keep in mind that concatenating all the product descriptions into a single brand description is naïve. In the future, we could reconsider and replace it with a better strategy.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> collections <span style="color:#f92672">import</span> defaultdict
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>statement <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">MATCH (brand:Brand { brandId: $id })-[has_product:HAS_PRODUCT]-&gt;(product:Product)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">WITH collect(product.description)[0..20000] as descriptions, brand
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">RETURN brand, descriptions
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create a session to run all the neo4j queries</span>
</span></span><span style="display:flex;"><span>session <span style="color:#f92672">=</span> db<span style="color:#f92672">.</span>session()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>brand_descriptions <span style="color:#f92672">=</span> defaultdict(list)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>f <span style="color:#f92672">=</span> open(<span style="color:#e6db74">&#39;brand_descriptions.csv&#39;</span>, <span style="color:#e6db74">&#39;w&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># csv file with: brand id, brand name, brand description</span>
</span></span><span style="display:flex;"><span>f<span style="color:#f92672">.</span>write(<span style="color:#e6db74">&#34;brand_id,brand_name,description</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">n&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> brand_id <span style="color:#f92672">in</span> filtered_brand_ids:
</span></span><span style="display:flex;"><span>    brand_descriptions_neo4j <span style="color:#f92672">=</span> session<span style="color:#f92672">.</span>run(statement, id<span style="color:#f92672">=</span>brand_id)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> brand, descriptions <span style="color:#f92672">in</span> brand_descriptions_neo4j:
</span></span><span style="display:flex;"><span>        brand_name <span style="color:#f92672">=</span> brand[<span style="color:#e6db74">&#39;name&#39;</span>]
</span></span><span style="display:flex;"><span>        brand_descriptions[brand_id] <span style="color:#f92672">=</span> descriptions
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># concat product descriptions to build the brand description</span>
</span></span><span style="display:flex;"><span>    concated_descriptions <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(brand_descriptions[brand_id])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># pre-process descriptions</span>
</span></span><span style="display:flex;"><span>  	brand_description <span style="color:#f92672">=</span> pre_process(concated_descriptions)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    f<span style="color:#f92672">.</span>write(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>brand_id<span style="color:#e6db74">}</span><span style="color:#e6db74">,</span><span style="color:#e6db74">{</span>brand_name<span style="color:#e6db74">}</span><span style="color:#e6db74">,</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">&#34;</span>{str(brand_description)}\\<span style="color:#e6db74">&#34; </span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">n&#34;</span>)
</span></span><span style="display:flex;"><span>f<span style="color:#f92672">.</span>close()
</span></span></code></pre></div><h3 id="preparing-the-data">Preparing the data</h3>
<p>You might have noticed that each brand description is processed right before being written to the resulting CSV file.</p>
<p>There was nothing special when it comes to preparing the data. We are just replacing some special characters on the product descriptions to avoid having them on the final brand description, as they don&rsquo;t add any value. When training the model, we will also make sure to remove the most common English words (e.g. <em>a</em>, <em>or</em>, <em>the</em>) since they don&rsquo;t add any value either.</p>
<p>Finally, we convert all the text to lowercase since terms like <em>Red</em>, and <em>red</em> shouldn&rsquo;t be any different.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">pre_process</span>(brand_description):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># pontuaction</span>
</span></span><span style="display:flex;"><span>    symbols <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;!</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">&#34;</span><span style="color:#75715e">#$%&amp;()&#39;*+-.,/:;&lt;=&gt;?@[\\]^_`{|}~\\n\\r&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> symbols:
</span></span><span style="display:flex;"><span>        brand_description <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>char<span style="color:#f92672">.</span>replace(brand_description, i, <span style="color:#e6db74">&#39; &#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># lowercase</span>
</span></span><span style="display:flex;"><span>    brand_description <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>char<span style="color:#f92672">.</span>lower(brand_description)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> str(brand_description)
</span></span></code></pre></div><h3 id="model-training">Model training</h3>
<p>The data is now collected and pre-processed. Everything should be ready to train the model. As we have already explained earlier, we will use TF-IDF to measure the weights for each term (or feature) within each document (i.e. brand description), and then Cosine Similarity to find similar documents.</p>
<p>First things first, let&rsquo;s read the content of the CSV file into a pandas data frame.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>brand_descriptions_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#34;brand_descriptions.csv&#34;</span>)
</span></span></code></pre></div><p>We then took advantage of the <code>TfidfVectorizer</code> class from <code>sklearn</code> to build a TF-IDF matrix. You can find all the possible parameters on <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html">TfidfVectorizer&rsquo;s documentation</a>, but I will enumerate the few that were used:</p>
<ul>
<li><strong>analyzer</strong>: <code>word</code> - features (i.e. columns) will be made up of words or n-grams.</li>
<li><strong>ngram_range</strong>: <code>(1,4)</code> - features as n-grams from 1 to 4, e.g. <em>hello</em>, <em>hello world</em>, <em>hello world dinis</em>, <em>hello world dinis peixoto</em>.</li>
<li><strong>min_df</strong>: <code>0.05</code> - minimum document frequency, i.e. ignore terms that have a document frequency lower than the threshold (5%).</li>
<li><strong>stop_words</strong>: <code>english</code> - remove common english words from the description as they won&rsquo;t add value.</li>
</ul>
<p>We have also printed some of the features to show that they are actually quite relevant and descriptive of the products that a brand may have. They also include examples of different n-grams.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> TfidfVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tfidf <span style="color:#f92672">=</span> TfidfVectorizer(
</span></span><span style="display:flex;"><span>  analyzer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;word&#39;</span>, ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">4</span>),
</span></span><span style="display:flex;"><span>  min_df<span style="color:#f92672">=</span><span style="color:#ae81ff">0.05</span>, stop_words<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;english&#39;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tfidf_matrix <span style="color:#f92672">=</span> tfidf<span style="color:#f92672">.</span>fit_transform(brand_descriptions_df[<span style="color:#e6db74">&#39;description&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># some examples: white wool, low sneakers, stainless, </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># round glasses, multicolor synthetic, trousers</span>
</span></span><span style="display:flex;"><span>feature_names <span style="color:#f92672">=</span> tfidf<span style="color:#f92672">.</span>get_feature_names()
</span></span></code></pre></div><p>Then we compare each of the brand vectors, i.e. the rows in the TF-IDF matrix. As we have seen earlier, Cosine Similarity does not take into account the magnitude of the vectors. The <code>TfidfVectorizer</code> returns normalized weights (magnitude of 1), so the Linear Kernel is sufficient to calculate the similarity values that we are looking for.</p>
<p>We could be using the <code>cosine_similarity</code> from <code>sklearn</code> instead of <code>linear_kernel</code>. We would, however, be calculating the vector&rsquo;s magnitude without the need to, which can have a considerable impact on the performance when using a matrix with high dimensions. I&rsquo;d suggest further reading on this and the different pairwise metrics used to evaluate distances that <code>sklearn</code> provides - <a href="https://scikit-learn.org/stable/modules/metrics.html">Pairwise metrics, Affinities and Kernels</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics.pairwise <span style="color:#f92672">import</span> linear_kernel
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cosine_similarities <span style="color:#f92672">=</span> linear_kernel(tfidf_matrix, tfidf_matrix)
</span></span></code></pre></div><p>Now that we have the matrix of Cosine Similarities, the only thing left to do is build a dictionary with the top N recommendations for each brand. Remember that the most similar brand is the brand itself? That&rsquo;s exactly what we are doing in the last line, excluding it from the final recommendations.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>results <span style="color:#f92672">=</span> {} <span style="color:#75715e"># (brand_id : [(score, similar_brand_id)]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> idx, row <span style="color:#f92672">in</span> brand_descriptions_df<span style="color:#f92672">.</span>iterrows(): 
</span></span><span style="display:flex;"><span>    similar_indices <span style="color:#f92672">=</span> cosine_similarities[idx]<span style="color:#f92672">.</span>argsort()[:<span style="color:#f92672">-</span><span style="color:#ae81ff">15</span>:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    similar_items <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>      (cosine_similarities[idx][i], brand_descriptions_df[<span style="color:#e6db74">&#39;brand_id&#39;</span>][i]) 
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> similar_indices
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    results[row[<span style="color:#e6db74">&#39;brand_id&#39;</span>]] <span style="color:#f92672">=</span> similar_items[<span style="color:#ae81ff">1</span>:] <span style="color:#75715e"># excludes the brand itself</span>
</span></span></code></pre></div><h3 id="evaluation">Evaluation</h3>
<p>And we have finally reached the most fun part, actually providing brand recommendations. We start by creating a <code>recommend</code> function that gives the top N recommended brands (up to 14) based on a brand id received as input.</p>
<p>Note that model evaluation consists of evaluating a model&rsquo;s performance by comparing the results on the training set with the expected results from the test set (i.e. data not seen by the model). The thing is that I didn&rsquo;t have a curated list of brands that should be recommended together, so I just had a look at the results and tried to reach some conclusions around them. Evaluating the performance of recommendations is a really common issue and one of the main challenges of recommendation systems.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">recommend</span>(id, num<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>): <span style="color:#75715e"># max is 15 - 1 = 14</span>
</span></span><span style="display:flex;"><span>    recs <span style="color:#f92672">=</span> results[id][:num]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> rec <span style="color:#f92672">in</span> recs:
</span></span><span style="display:flex;"><span>        score, brand_id <span style="color:#f92672">=</span> rec[<span style="color:#ae81ff">0</span>], rec[<span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        brand_name <span style="color:#f92672">=</span> brand_descriptions_df<span style="color:#f92672">.</span>loc[
</span></span><span style="display:flex;"><span>          brand_descriptions_df[<span style="color:#e6db74">&#39;brand_id&#39;</span>] <span style="color:#f92672">==</span> brand_id, <span style="color:#e6db74">&#39;brand_name&#39;</span>
</span></span><span style="display:flex;"><span>        ]<span style="color:#f92672">.</span>iloc[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Brand </span><span style="color:#e6db74">{</span>brand_name<span style="color:#e6db74">}</span><span style="color:#e6db74"> (</span><span style="color:#e6db74">{</span>brand_id<span style="color:#e6db74">}</span><span style="color:#e6db74">) with score </span><span style="color:#e6db74">{</span>str(score)<span style="color:#e6db74">}</span><span style="color:#e6db74"> &#34;</span>)
</span></span></code></pre></div><p>Without further ado, let&rsquo;s see the results and reach some conclusions around them.</p>
<p><img alt="Results" src="/img/posts/brand-recommendations-tfidf/recs.png"></p>
<ol>
<li><strong>Nike</strong> and <strong>Jordan</strong> is really interesting since they belong to the same parent company. Also, Nike recommendations seem to be decent, to say the least.</li>
<li>Sister brands are recommended together, e.g. multiple <strong>Adidas collaborations</strong> and <strong>COMME DES GARÇONS</strong> labels.</li>
<li>Great to see that every recommendation for <strong>Tommy Junior</strong> is indeed a Junior/Kids brand.</li>
<li><strong>Gucci</strong> and other related (I mean <em>expensive</em>) brands also together - <strong>Versace</strong>, <strong>Givenchy</strong>, <strong>Balenciaga</strong>, <strong>Prada</strong> and <strong>Burberry</strong>.</li>
<li>I only own 2 sneaker brands: <strong>Adidas</strong> and <strong>Veja</strong>, so I&rsquo;m quite happy with the Adidas recommendations even without <strong>Nike</strong> being there.</li>
<li>Every recommendation for <strong>Rayban</strong> is also an eyewear brand.</li>
</ol>
<h2 id="conclusion-and-next-steps">Conclusion and next steps</h2>
<p>I guess this was only the beginning of my Machine Learning journey. What I built here is really simple but, in a way, tackles an issue that I found that needed to be tackled. It had a real-world use-case, which was what I was looking for. On top of that, even though the model is simple, the results ended up being quite interesting.</p>
<p>The next step is setting up a pipeline that trains and deploys the model so that I can explore a little bit more the MLOps world. In fact, I have already this in place (it&rsquo;s available in the same <a href="https://github.com/dinispeixoto/related-brands-mlops">Github repository</a>) and plan to write about the process soon.</p>
<p>My initial goal was to build a recommendations model based on collaborative filtering (it seems to be a lot more fun), so I might work on that in the future and combine both models into a <em>Hybrid Recommendations System</em>. Before doing so, I still have to figure out a way of evaluating the models to check whether the recommendations that it is making actually make any sense, other than my fashion judgement on which brands should be recommended together.</p>
]]></content>
        </item>
        
    </channel>
</rss>
